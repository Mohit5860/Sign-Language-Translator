{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 21:21:55.819449: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-28 21:21:55.820108: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 21:21:55.822838: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-28 21:21:55.830391: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-28 21:21:55.841685: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-28 21:21:55.844778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-28 21:21:55.853661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 21:21:56.471014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load('./last/x_train.npy')\n",
    "y_train = np.load('./last/y_train.npy')\n",
    "x_val = np.load('./last/x_val.npy')\n",
    "y_val = np.load('./last/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(225,)))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(200, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam( learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.0149 - loss: 5.5658 - val_accuracy: 0.0580 - val_loss: 4.7069\n",
      "Epoch 2/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0662 - loss: 4.6002 - val_accuracy: 0.1276 - val_loss: 4.1327\n",
      "Epoch 3/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.1274 - loss: 4.0758 - val_accuracy: 0.1958 - val_loss: 3.6659\n",
      "Epoch 4/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.1933 - loss: 3.6223 - val_accuracy: 0.2825 - val_loss: 3.2077\n",
      "Epoch 5/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.2648 - loss: 3.2111 - val_accuracy: 0.3378 - val_loss: 2.8947\n",
      "Epoch 6/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3200 - loss: 2.9061 - val_accuracy: 0.3963 - val_loss: 2.6239\n",
      "Epoch 7/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3560 - loss: 2.7016 - val_accuracy: 0.4465 - val_loss: 2.3891\n",
      "Epoch 8/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3972 - loss: 2.4966 - val_accuracy: 0.4850 - val_loss: 2.2267\n",
      "Epoch 9/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4292 - loss: 2.3420 - val_accuracy: 0.5209 - val_loss: 2.0841\n",
      "Epoch 10/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4603 - loss: 2.2033 - val_accuracy: 0.5584 - val_loss: 1.9433\n",
      "Epoch 11/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4880 - loss: 2.0869 - val_accuracy: 0.5778 - val_loss: 1.8505\n",
      "Epoch 12/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5093 - loss: 1.9915 - val_accuracy: 0.6079 - val_loss: 1.7247\n",
      "Epoch 13/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5334 - loss: 1.8802 - val_accuracy: 0.6153 - val_loss: 1.6942\n",
      "Epoch 14/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5509 - loss: 1.8079 - val_accuracy: 0.6404 - val_loss: 1.5786\n",
      "Epoch 15/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5693 - loss: 1.7266 - val_accuracy: 0.6613 - val_loss: 1.5035\n",
      "Epoch 16/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5821 - loss: 1.6625 - val_accuracy: 0.6744 - val_loss: 1.4490\n",
      "Epoch 17/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6019 - loss: 1.5842 - val_accuracy: 0.6910 - val_loss: 1.3804\n",
      "Epoch 18/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6182 - loss: 1.5296 - val_accuracy: 0.7070 - val_loss: 1.3290\n",
      "Epoch 19/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6230 - loss: 1.4820 - val_accuracy: 0.7013 - val_loss: 1.3144\n",
      "Epoch 20/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6394 - loss: 1.4296 - val_accuracy: 0.7219 - val_loss: 1.2443\n",
      "Epoch 21/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6465 - loss: 1.3854 - val_accuracy: 0.7329 - val_loss: 1.1958\n",
      "Epoch 22/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6552 - loss: 1.3394 - val_accuracy: 0.7356 - val_loss: 1.1787\n",
      "Epoch 23/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6667 - loss: 1.3016 - val_accuracy: 0.7458 - val_loss: 1.1357\n",
      "Epoch 24/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6727 - loss: 1.2690 - val_accuracy: 0.7619 - val_loss: 1.0934\n",
      "Epoch 25/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6831 - loss: 1.2343 - val_accuracy: 0.7663 - val_loss: 1.0610\n",
      "Epoch 26/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6893 - loss: 1.2071 - val_accuracy: 0.7575 - val_loss: 1.0737\n",
      "Epoch 27/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6960 - loss: 1.1747 - val_accuracy: 0.7752 - val_loss: 1.0291\n",
      "Epoch 28/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7078 - loss: 1.1225 - val_accuracy: 0.7806 - val_loss: 0.9882\n",
      "Epoch 29/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7078 - loss: 1.1096 - val_accuracy: 0.7866 - val_loss: 0.9672\n",
      "Epoch 30/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7175 - loss: 1.0708 - val_accuracy: 0.7845 - val_loss: 0.9676\n",
      "Epoch 31/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7203 - loss: 1.0688 - val_accuracy: 0.7912 - val_loss: 0.9286\n",
      "Epoch 32/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7301 - loss: 1.0330 - val_accuracy: 0.7943 - val_loss: 0.9245\n",
      "Epoch 33/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7327 - loss: 1.0161 - val_accuracy: 0.7940 - val_loss: 0.9280\n",
      "Epoch 34/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7353 - loss: 0.9954 - val_accuracy: 0.7999 - val_loss: 0.8915\n",
      "Epoch 35/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7395 - loss: 0.9805 - val_accuracy: 0.8030 - val_loss: 0.8933\n",
      "Epoch 36/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7420 - loss: 0.9704 - val_accuracy: 0.8070 - val_loss: 0.8741\n",
      "Epoch 37/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7474 - loss: 0.9417 - val_accuracy: 0.7982 - val_loss: 0.8911\n",
      "Epoch 38/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7488 - loss: 0.9466 - val_accuracy: 0.8116 - val_loss: 0.8464\n",
      "Epoch 39/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7547 - loss: 0.9176 - val_accuracy: 0.8155 - val_loss: 0.8287\n",
      "Epoch 40/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7577 - loss: 0.9010 - val_accuracy: 0.8198 - val_loss: 0.8155\n",
      "Epoch 41/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7664 - loss: 0.8741 - val_accuracy: 0.8147 - val_loss: 0.8387\n",
      "Epoch 42/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7642 - loss: 0.8763 - val_accuracy: 0.8197 - val_loss: 0.8012\n",
      "Epoch 43/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7681 - loss: 0.8523 - val_accuracy: 0.8217 - val_loss: 0.8058\n",
      "Epoch 44/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7711 - loss: 0.8453 - val_accuracy: 0.8213 - val_loss: 0.8007\n",
      "Epoch 45/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7743 - loss: 0.8405 - val_accuracy: 0.8207 - val_loss: 0.8028\n",
      "Epoch 46/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7746 - loss: 0.8250 - val_accuracy: 0.8294 - val_loss: 0.7733\n",
      "Epoch 47/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7819 - loss: 0.8039 - val_accuracy: 0.8314 - val_loss: 0.7618\n",
      "Epoch 48/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7821 - loss: 0.7948 - val_accuracy: 0.8331 - val_loss: 0.7477\n",
      "Epoch 49/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7858 - loss: 0.7828 - val_accuracy: 0.8341 - val_loss: 0.7376\n",
      "Epoch 50/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7919 - loss: 0.7659 - val_accuracy: 0.8361 - val_loss: 0.7408\n",
      "Epoch 51/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7869 - loss: 0.7756 - val_accuracy: 0.8368 - val_loss: 0.7491\n",
      "Epoch 52/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7947 - loss: 0.7478 - val_accuracy: 0.8348 - val_loss: 0.7427\n",
      "Epoch 53/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7947 - loss: 0.7418 - val_accuracy: 0.8379 - val_loss: 0.7366\n",
      "Epoch 54/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7928 - loss: 0.7418 - val_accuracy: 0.8392 - val_loss: 0.7266\n",
      "Epoch 55/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7972 - loss: 0.7301 - val_accuracy: 0.8417 - val_loss: 0.7143\n",
      "Epoch 56/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7980 - loss: 0.7266 - val_accuracy: 0.8388 - val_loss: 0.7339\n",
      "Epoch 57/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8030 - loss: 0.7099 - val_accuracy: 0.8437 - val_loss: 0.7089\n",
      "Epoch 58/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8032 - loss: 0.7017 - val_accuracy: 0.8413 - val_loss: 0.7263\n",
      "Epoch 59/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8037 - loss: 0.7007 - val_accuracy: 0.8504 - val_loss: 0.6960\n",
      "Epoch 60/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8092 - loss: 0.6815 - val_accuracy: 0.8488 - val_loss: 0.6942\n",
      "Epoch 61/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8073 - loss: 0.6815 - val_accuracy: 0.8446 - val_loss: 0.7074\n",
      "Epoch 62/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8116 - loss: 0.6745 - val_accuracy: 0.8499 - val_loss: 0.6925\n",
      "Epoch 63/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8123 - loss: 0.6712 - val_accuracy: 0.8544 - val_loss: 0.6713\n",
      "Epoch 64/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8160 - loss: 0.6520 - val_accuracy: 0.8544 - val_loss: 0.6799\n",
      "Epoch 65/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8146 - loss: 0.6600 - val_accuracy: 0.8490 - val_loss: 0.6960\n",
      "Epoch 66/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8188 - loss: 0.6405 - val_accuracy: 0.8514 - val_loss: 0.6777\n",
      "Epoch 67/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8187 - loss: 0.6431 - val_accuracy: 0.8589 - val_loss: 0.6665\n",
      "Epoch 68/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8233 - loss: 0.6263 - val_accuracy: 0.8569 - val_loss: 0.6659\n",
      "Epoch 69/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8248 - loss: 0.6250 - val_accuracy: 0.8583 - val_loss: 0.6569\n",
      "Epoch 70/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8219 - loss: 0.6289 - val_accuracy: 0.8597 - val_loss: 0.6651\n",
      "Epoch 71/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8259 - loss: 0.6139 - val_accuracy: 0.8623 - val_loss: 0.6421\n",
      "Epoch 72/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8268 - loss: 0.6120 - val_accuracy: 0.8604 - val_loss: 0.6503\n",
      "Epoch 73/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.6041 - val_accuracy: 0.8587 - val_loss: 0.6537\n",
      "Epoch 74/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8299 - loss: 0.5932 - val_accuracy: 0.8647 - val_loss: 0.6445\n",
      "Epoch 75/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8304 - loss: 0.5904 - val_accuracy: 0.8616 - val_loss: 0.6543\n",
      "Epoch 76/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8315 - loss: 0.5890 - val_accuracy: 0.8642 - val_loss: 0.6414\n",
      "Epoch 77/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8323 - loss: 0.5839 - val_accuracy: 0.8662 - val_loss: 0.6345\n",
      "Epoch 78/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8322 - loss: 0.5791 - val_accuracy: 0.8660 - val_loss: 0.6287\n",
      "Epoch 79/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8353 - loss: 0.5687 - val_accuracy: 0.8663 - val_loss: 0.6306\n",
      "Epoch 80/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8344 - loss: 0.5749 - val_accuracy: 0.8665 - val_loss: 0.6317\n",
      "Epoch 81/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8319 - loss: 0.5759 - val_accuracy: 0.8647 - val_loss: 0.6404\n",
      "Epoch 82/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8386 - loss: 0.5552 - val_accuracy: 0.8669 - val_loss: 0.6334\n",
      "Epoch 83/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8385 - loss: 0.5532 - val_accuracy: 0.8678 - val_loss: 0.6318\n",
      "Epoch 84/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8369 - loss: 0.5616 - val_accuracy: 0.8704 - val_loss: 0.6219\n",
      "Epoch 85/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8418 - loss: 0.5478 - val_accuracy: 0.8645 - val_loss: 0.6400\n",
      "Epoch 86/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8440 - loss: 0.5375 - val_accuracy: 0.8689 - val_loss: 0.6263\n",
      "Epoch 87/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8445 - loss: 0.5349 - val_accuracy: 0.8693 - val_loss: 0.6236\n",
      "Epoch 88/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8409 - loss: 0.5401 - val_accuracy: 0.8687 - val_loss: 0.6294\n",
      "Epoch 89/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8426 - loss: 0.5421 - val_accuracy: 0.8683 - val_loss: 0.6376\n",
      "Epoch 90/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8414 - loss: 0.5423 - val_accuracy: 0.8705 - val_loss: 0.6285\n",
      "Epoch 91/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8461 - loss: 0.5293 - val_accuracy: 0.8715 - val_loss: 0.6299\n",
      "Epoch 92/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8461 - loss: 0.5224 - val_accuracy: 0.8711 - val_loss: 0.6251\n",
      "Epoch 93/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8497 - loss: 0.5098 - val_accuracy: 0.8650 - val_loss: 0.6540\n",
      "Epoch 94/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8462 - loss: 0.5243 - val_accuracy: 0.8711 - val_loss: 0.6161\n",
      "Epoch 95/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8501 - loss: 0.5093 - val_accuracy: 0.8737 - val_loss: 0.6105\n",
      "Epoch 96/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8470 - loss: 0.5186 - val_accuracy: 0.8742 - val_loss: 0.6080\n",
      "Epoch 97/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8500 - loss: 0.5090 - val_accuracy: 0.8724 - val_loss: 0.6227\n",
      "Epoch 98/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8530 - loss: 0.4966 - val_accuracy: 0.8730 - val_loss: 0.6186\n",
      "Epoch 99/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8516 - loss: 0.5030 - val_accuracy: 0.8750 - val_loss: 0.6057\n",
      "Epoch 100/100\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8554 - loss: 0.4798 - val_accuracy: 0.8727 - val_loss: 0.6122\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train , batch_size= 128, epochs= 100, verbose= 1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./last/x_test.npy')\n",
    "y_test = np.load('./last/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.5808\n",
      "Test Accuracy: 87.27%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
